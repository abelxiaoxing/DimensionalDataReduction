# 赛题介绍
## 一、赛题任务背景

在图像识别、生物信息分析、材料科学等领域中，高维数据普遍存在，但其带来的“维度灾难”严重影响计算效率与模型性能。因此，需要使用高性能的降维算法，在保留主要信息的同时降低数据维度，从而提升任务执行效率和准确率。

你需要针对以下三类典型数据，分别设计降维算法，并完成分类任务与性能评估。

---

## 二、数据类型与说明

### 1. 手写体图像数据（MNIST）

- 文件名：`mnist-test-x.knd`
- 数据结构：
  - 第一行第一列是 `#no:truth`，表示后续每一行的第一个元素是样本编号和真实标签（如 `1:7` 表示第1个样本的真实数字为7）
  - 后续每行代表一个28×28像素的手写数字图像，共784个灰度值（0~1之间），总共有10,000个样本
- 原始维度：784维
- 应用任务：手写数字识别（0~9）

---

### 2. 葡萄酒数据（Wine Classification）

- 文件名：`wine.data`
- 数据结构：
  - 共178个样本，每行为一种葡萄酒
  - 第一列为类别标签（1、2、3），代表不同产地
  - 后续13列为特征参数（如酒精含量、镁含量等）
- 原始维度：13维
- 应用任务：葡萄酒产地分类

---

### 3. 材料拉曼光谱数据（Raman Spectra）

- 目录：`excellent_oriented/` 下有7645个 `.txt` 文件
- 文件命名示例：`Actinolite__R040063-4__Raman__514__0__ccw__Raman_Data_RAW__1508`
  - 包含矿物名称、样品编号、激光波长、入射角度、偏振方向、原始/预处理标志
- 数据格式：
  - 每个文件前12行为注释
  - 第13行开始为两列数据：第一列为拉曼位移（cm⁻¹），第二列为散射强度
- 处理方式区分：
  - RAW数据：原始未处理，可能存在噪声、基线漂移等问题
  - Processed数据：已校正荧光背景、平滑噪声、归一化强度等
- 数据对齐要求：
  - 对所有样本统一取相同范围（如200~1000 cm⁻¹）
  - 插值拟合后统一采样为1000个点
- 原始维度：1000维
- 应用任务：材料类别识别（如阳起石、方解石等）

---

## 三、任务要求

对于每类数据，需完成以下三个子任务：

### 1. 数据降维

- 使用合适的降维算法（如 PCA、t-SNE、UMAP、NMF、Autoencoder 等）
- 将数据从原始维度降至 2~100 维之间的指定维度
- 选择最佳算法并说明理由

### 2. 分类建模

- 在降维后的低维空间上，构建分类器（如 SVM、随机森林、神经网络等）
- 完成对应的应用任务（手写识别、产地分类、材料识别）

### 3. 性能评估

评估指标及其权重如下：

| 指标 | 权重 | 说明 |
|------|------|------|
| 分类准确率 | 50% | 分类任务的准确率 |
| 降维重构误差 | 20% | 如 MSE、SNR 等 |
| 降维比率 | 10% | 降维后维度 / 原始维度 |
| 运行时间 | 10% | 算法运行耗时 |
| 可视化效果 | 10% | 二维/三维空间中分布是否可解释 |

---

## 四、可视化与解释需求

请对降维后的特征向量进行可视化与解释：

- **手写体图像**：例如使用 NMF 可以得到若干“基图像”，这些图像是否能组合还原出原始图像？
- **葡萄酒数据**：降维后能否通过特征系数区分出不同产地？
- **光谱数据**：降维后的特征是否能有效反映材料类别差异？

---

## 五、任务要求
根据上述描述，完成以下工作：

1. 针对每类数据，提出适合的降维算法，并说明理由
2. 实现降维与分类流程
3. 输出性能评估结果（准确率、MSE、运行时间等）
4. 提供可视化结果与解释
5. 提供一个 demo 系统，支持用户输入新的样本数据（格式一致），输出重建误差
6. 重建误差越小，得分越高

---

# 技术方案及使用方法

## 数据与权重下载
下载压缩包,解压datas数据文件夹和models权重文件夹到当前根目录

通过网盘分享的文件：DimensionalDataReduction.7z
链接: https://pan.baidu.com/s/1URyOUMD2c_p_Nn9_7ZjfsA?pwd=abel 提取码: abel

---

## 一、 针对手写体图像（MNIST）与葡萄酒特征的统一解决方案：语义引导与自适应正则化深度表征网络 (SGAR-DRN)

为了高效处理图像及结构化特征数据，我们提出了一种统一的“语义引导与自适应正则化深度表征网络”（Semantically-Guided and Adaptively-Regularized Deep Representation Network, SGAR-DRN）。该网络由两核心模块构成：改进的变分自编码器（VAE）用于降维，以及改进的多层感知机（MLP）作为分类头。

### 1. 核心降维引擎：语义增强型变分自编码器 (Semantics-Enhanced VAE, SE-VAE)

*   **创新点1：监督引导的潜在空间解耦与特征增强 (Supervised Latent Space Decoupling and Feature Enhancement)**：
    *   **描述：** 传统VAE的潜变量学习主要受重构任务驱动，可能导致与分类任务不完全对齐的表征。我们创新性地在VAE的潜变量空间中**嵌入一个动态可调的分类引导模块 (Dynamic Classification Guidance Module)**。该模块以一个轻量级分类器分支形式存在，其损失函数（如交叉熵损失）**直接反向传播并作用于编码器**。这引入了强监督信号，迫使潜变量不仅要捕获数据的内在流形结构以实现高质量重构，**更要主动学习具有类别区分性的语义特征**，实现潜在空间的“任务导向型”重塑。编码器可采用多尺度卷积结构（针对MNIST）以捕获从局部到全局的图像特征。

*   **创新点2：自适应多目标损失平衡机制 (Adaptive Multi-Objective Loss Balancing Mechanism)**：
    *   **描述：** VAE的训练涉及重构损失、KL散度（正则化潜空间分布）以及新增的分类损失。这三者之间存在复杂的平衡关系。我们设计了一种**基于梯度范数或不确定性加权的自适应损失平衡策略**。该策略能够**动态调整各损失项在总损失函数中的权重**，避免某一损失主导训练过程，确保模型在重构保真度、潜空间平滑性与分类判别力之间达到帕累托最优，从而提升整体性能和训练稳定性。
     $$\mathcal{L}_{\text{total}} = w_1 \cdot \mathcal{L}_{\text{reconstruction}} + w_2 \cdot \mathcal{L}_{\text{KL}} + w_3 \cdot \mathcal{L}_{\text{classification}}$$
     其中，\(w_i\) 根据梯度范数或不确定性动态调整。

*   **创新点3：潜变量空间的语义锚定与可解释性增强 (Latent Space Semantic Anchoring and Interpretability Enhancement)**：
    *   **描述：** 通过分类引导模块的引入，潜变量的特定维度或区域将与特定类别语义强相关。这使得降维后的低维空间**不仅是数据的压缩表示，更是具有明确语义意义的“概念空间”**。这为后续分类任务提供了更纯净、更具判别力的特征，并为可视化分析提供了更强的可解释性基础。

### 2. 高性能分类头：深度残差感知网络 (Deep Residual Perceptron Network, DRPN)

*   **创新点1：残差捷径赋能深度结构 (Residual Shortcuts for Deep Architectures)**：
    *   **描述：** 在传统的MLP基础上，我们引入了**跨层残差连接 (Cross-Layer Residual Connections)**。这允许梯度在深层网络中更顺畅地传播，有效缓解梯度消失/爆炸问题，使得构建更深、表达能力更强的MLP成为可能，从而捕捉降维特征中更复杂的非线性模式。
     $$y = \text{Activation}(W \cdot x + b) + x$$

*   **创新点2：SELU激活函数的自归一化特性 (Self-Normalizing Properties of SELU Activation)**：
    *   **描述：** 采用**SELU (Scaled Exponential Linear Units) 激活函数**替代常用的ReLU及其变体。SELU具有独特的自归一化特性，能够将神经元激活值自动推向零均值和单位方差，从而在训练过程中**内在抵抗梯度消失/爆炸，并加速网络收敛**，减少对批量归一化（Batch Normalization）等外部正则化手段的依赖。

### 应用场景与特定优化：

#### A. MNIST手写体识别
*   **降维与分类：** SE-VAE将784维像素信息（编码器采用多尺度卷积结构）压缩至低维语义空间，DRPN在该空间上进行高效数字识别。
*   **注意力机制：** 可在DRPN的输入层引入自注意力模块，增强对降维后特征的相关性建模，进一步提升分类精度。

#### B. 葡萄酒产地分类
*   **降维与分类：** SE-VAE从13维化学特征中提取与产地相关的核心表征，DRPN据此进行精准分类。
*   **SE-VAE针对小样本的优化：**
    *   **潜在空间正则化：** 针对小样本数据，可引入核密度估计（KDE）等方法约束潜在空间分布，增强泛化能力。
    *   **特征交互建模：** 在编码器中融入化学特征的先验知识（如pH值与酒精浓度的交互效应），通过多头自注意力机制等方式建模特征间的非线性关系。
    *   **动态降维选择：** 设计自适应降维模块，根据分类任务需求动态选择2~10维的潜在空间维度。
*   **DRPN针对小样本的优化：**
    *   **网络精简：** 针对Wine数据进一步精简DRPN的网络层数（例如3层），降低过拟合风险。
    *   **正则化：** 引入DropConnect等正则化技术，随机丢弃权重连接，提升小样本场景的泛化能力。
*   **数据增强：**
    *   针对13维特征，实施随机扰动（±5%幅度）、特征掩码（随机置零1~2维）。
    *   使用SMOTE算法生成合成样本，平衡类别分布。

---

## 二、 针对拉曼光谱的特化解决方案：物理信息增强型混合智能拉曼光谱分析框架 (PIHI-RSA)

拉曼光谱数据具有高维、信噪比低、基线漂移以及小样本等挑战。为此，我们设计了一个多阶段、深度定制的分析框架。

### 1. 预处理核心：高保真物理信息嵌入预处理模块 (High-Fidelity Physics-Informed Preprocessing Module)

*   **创新点1：Voigt线型函数引导的物理特性保持插值 (Voigt Profile-Guided Physics-Preserving Interpolation)**：
    *   **描述：** 光谱对齐与维度统一是基础。我们摒弃简单的线性或样条插值，创新性地采用**Voigt线型函数（高斯与洛伦兹峰形的卷积）对原始光谱进行精细拟合与峰位校准**。在插值至统一1000维的过程中，**该拟合模型提供的光谱峰形参数（如峰位、峰高、半高宽、峰面积）作为物理先验信息被融入插值算法**。这确保了插值结果不仅在数值上平滑，更在物理意义上保持了光谱的真实峰形特征与相对强度关系，显著提升了数据的保真度和后续分析的可靠性。
    *   Voigt函数形式：
         $$V(x; \sigma, \gamma) = \int_{-\infty}^{\infty} G(t; \sigma) L(x - t; \gamma) dt$$
         其中，\(G(t; \sigma)\)为高斯分布，\(L(x; \gamma)\)为洛伦兹分布。

### 2. 降维与分类集成：PCA引导的双通道混合降维与元学习增强分类系统 (PCA-Guided Dual-Channel Hybrid Dimensionality Reduction and Meta-Learning Enhanced Classification System)

*   **创新点2：混合降维架构——线性全局感知与非线性深度挖掘 (Hybrid DR: Linear Global Perception & Non-linear Deep Mining)**：
    *   **描述：** 我们构建了一个**PCA预处理 + 深度非线性映射的混合降维架构**。
        1.  **第一阶段 (PCA)：** 利用主成分分析（PCA）对经过Voigt物理信息嵌入预处理后的1000维光谱数据进行初步的全局线性特征提取和噪声滤除，捕捉数据的主要变异方向（例如，降至50维），实现对高维空间的初步“净化”与“聚焦”。
        2.  **第二阶段 (深度非线性映射)：** 随后，**PCA降维后的特征将作为输入，送入一个精简高效的深度非线性映射模块（如深度残差自编码器 Res-AE、MLP或小型CNN）进行深度的非线性特征变换与再提纯**（例如，进一步降至2-50维）。这能挖掘PCA无法捕捉的复杂非线性关联，进一步压缩信息并提升特征的判别力。此设计兼顾了PCA的计算高效性、对线性结构的强大捕捉能力以及神经网络的强大非线性拟合能力。
            *   一个可能的Res-AE结构示例：
                 $$h = \text{ReLU}(W_1 \cdot x_{pca} + b_1), \quad z = h + \text{ReLU}(W_2 \cdot h + b_2)$$

*   **创新点3：面向光谱特性的高级数据增强策略 (Spectrum-Aware Advanced Data Augmentation)**：
    *   **描述：** 为克服小样本限制并增强模型对真实世界光谱变化的鲁棒性，我们实施一套精心设计的在线数据增强流程：
        *   **随机频谱校准模拟 (Random Spectral Calibration Simulation)：** 对光谱进行微小的随机频移（例如±3-5个波数单位），模拟仪器校准误差或环境温度变化。
        *   **动态强度与基线扰动 (Dynamic Intensity & Baseline Perturbation)：** 对光谱整体强度进行随机缩放（例如±10%），并叠加不同形态（如多项式、正弦）的随机基线漂移，模拟样品浓度变化、荧光背景及仪器噪声。
        *   **特征区域随机掩蔽 (Characteristic Region Random Masking)：** 随机掩蔽光谱中的部分特征峰区域（例如10%数据点），迫使模型学习利用更广泛的光谱信息进行判断，而非过度依赖少数几个强峰。
        *   **信噪比可控的高斯白噪声注入 (SNR-Controlled Additive White Gaussian Noise)：** 根据预估的实际信噪比范围（例如3dB），向光谱数据中添加可控水平的高斯白噪声，提升模型在低信噪比条件下的稳定性。

### 3. 分类模型：高效MLP

*   **描述：** 在混合降维后得到的低维特征基础上，使用一个浅层但高效的多层感知机（MLP）进行材料类别的最终分类。
*   **架构：** 例如，包含2个全连接层（如128和64个神经元），并采用Leaky ReLU等激活函数以缓解梯度消失问题并增强非线性表达。

---

## 三、通用优势与评估维度

*   **分类性能 (主导)：** 通过上述创新设计，预期在各类数据集上实现业界领先的分类准确率、召回率和F1分数。
*   **重构误差 (SE-VAE)：** 对于采用VAE的MNIST和Wine数据，将严格评估其低维表示对原始数据的重构保真度（例如MSE），确保信息损失最小化。支持输入新样本进行实时重建与误差评估。
*   **降维效率与比率：** 实现高降维比（例如从784维降至2-100维），同时兼顾降维过程的计算效率（运行时间）。
*   **可视化效果：** 利用t-SNE或UMAP等技术，将降维后的2D/3D特征进行可视化，直观展示类别区分性、潜在空间结构以及SE-VAE的语义锚定效果。

## 四、总结
本方案通过一系列针对性的架构创新（SE-VAE, DRPN）、物理信息融合（Voigt拟合）以及混合降维策略（PCA+NN），旨在构建一个在分类性能、重构质量、运行效率和模型可解释性方面均表现卓越的智能化高维数据分析方法。

---

## 打包可执行文件命令
```bash
python -m nuitka --standalone --plugin-enable=tk-inter,matplotlib,pyzmq --windows-icon-from-ico=icon.ico --include-module=mnist_inference --include-module=raman_reduction --include-module=wine_inference --include-data-dir=./models=models --include-data-dir=./datas=datas --output-dir=. --output-filename=DimensionReduction --jobs=12 ./launcher.py